{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T01:10:27.575622Z",
     "start_time": "2023-11-06T01:10:23.612337Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('popular', quiet=True)\n",
    "import demoji\n",
    "from wordcloud import WordCloud\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import bigrams\n",
    "from nltk import FreqDist\n",
    "import spacy\n",
    "import string\n",
    "nltk.download(\"wordnet\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Perform necessary data preprocessing, e.g. removing punctuation and stop words, stemming, lemmatizing. You may use the outputs from previous weekly assignments. (10 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T01:43:45.022283Z",
     "start_time": "2023-11-06T01:43:45.014627Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "def collect_data():\n",
    "    text_file_pattern = \"*.txt\"  # You can adjust the pattern to match your file extensions\n",
    "    text_files = glob.glob(os.path.join(\"../nhs/content\", text_file_pattern))\n",
    "    data = {}\n",
    "    for file_path in text_files:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            file_name = os.path.basename(file_path)\n",
    "            file_content = file.read()\n",
    "            data[file_name] = file_content\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T01:43:45.722771Z",
     "start_time": "2023-11-06T01:43:45.416206Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = collect_data()\n",
    "text = \"\"\n",
    "for data in corpus:\n",
    "    text += \" \" + data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T01:43:56.338948Z",
     "start_time": "2023-11-06T01:43:56.334218Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    # Create a translation table to remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    # Use translate method to remove punctuation\n",
    "    cleaned_text = text.translate(translator)\n",
    "    return cleaned_text\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    nltk_stopwords = stopwords.words('english')\n",
    "    spacy_stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "    stop_words = (*nltk_stopwords, *spacy_stopwords, \"NHStxt\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "def apply_lemmitization(text):\n",
    "    tag_map = defaultdict(lambda : wordnet.NOUN)\n",
    "    tag_map['V'] = wordnet.VERB\n",
    "    tag_map['A'] = wordnet.ADJ\n",
    "    tag_map['R'] = wordnet.ADJ\n",
    "\n",
    "    lemmitizer = WordNetLemmatizer()\n",
    "    lemmitized_result = \"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    for token, tag in pos_tag(tokens):\n",
    "        lemma = lemmitizer.lemmatize(token, tag_map[tag[0]])\n",
    "        lemmitized_result = lemmitized_result + \" \" + lemma\n",
    "    return lemmitized_result\n",
    "\n",
    "def remove_emoji_and_smart_quotes(text):\n",
    "    # replacing emojis with description\n",
    "    text = demoji.replace_with_desc(text)\n",
    "    #Removing smart quotes\n",
    "    return text.replace(\"\"\", \"\\\"\").replace(\"\"\",\"\\\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T01:43:57.151857Z",
     "start_time": "2023-11-06T01:43:57.143287Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(text):\n",
    "    text = remove_emoji_and_smart_quotes(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_stop_words(text)\n",
    "    text = apply_lemmitization(text)\n",
    "    return text\n",
    "\n",
    "def apply_data_preprocessing_to_corpus(corpus):\n",
    "    new_corpus = {}\n",
    "    for idx, key in enumerate(corpus.keys()):\n",
    "        new_corpus[key] = data_preprocessing(corpus[key])\n",
    "        print(f\"idx: {idx}\")\n",
    "    return new_corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T01:43:58.441579Z",
     "start_time": "2023-11-06T01:43:58.204903Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_text = data_preprocessing(text)\n",
    "with open('week8_1.txt', 'w') as file:\n",
    "    file.write(f'{processed_text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate additional training data for your project by substituting different words with the same superordinate term in different sentence patterns. (30 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T01:42:02.797350Z",
     "start_time": "2023-11-06T01:42:02.787346Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T01:42:03.766888Z",
     "start_time": "2023-11-06T01:42:03.757834Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_simple_names(word):\n",
    "    words = []\n",
    "    for i in wn.synsets(word):\n",
    "        words += i.lemma_names()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:28:08.954827Z",
     "start_time": "2023-11-06T02:28:08.945819Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_additional_data(n=1):\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        new_text = \"\"\n",
    "        for token in word_tokenize(processed_text):\n",
    "            simples = get_simple_names(token)\n",
    "            if random.random() < 0.1 and len(simples) > 0 and len(simples) < 10:\n",
    "                new_text += random.choice(get_simple_names(token)) + \" \"\n",
    "            else:\n",
    "                new_text += token + \" \"\n",
    "        data.append(new_text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:28:37.411951Z",
     "start_time": "2023-11-06T02:28:37.283144Z"
    }
   },
   "outputs": [],
   "source": [
    "additional_data = create_additional_data(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:28:51.546102Z",
     "start_time": "2023-11-06T02:28:51.536012Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,\n",
       " 'Food colour hyperactivity Lung health check Carotid endarterectomy Middle East respiratory syndrome ')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(additional_data), additional_data[0][:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Perform context-free grammars and parsing on one of sentences in your project data.  (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T02:49:01.739646Z",
     "start_time": "2023-11-06T02:49:01.709703Z"
    }
   },
   "outputs": [],
   "source": [
    "import svgling\n",
    "import graphviz\n",
    "# svgling.disable_nltk_png()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T03:22:09.182590Z",
     "start_time": "2023-11-06T03:22:09.155346Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,568.0,168.0\" width=\"568px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"7.04225%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Do</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"3.52113%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"7.04225%\" x=\"7.04225%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">not</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">RB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10.5634%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.4507%\" x=\"14.0845%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">wash</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.3099%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"14.0845%\" x=\"22.5352%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">affected</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"29.5775%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"9.85915%\" x=\"36.6197%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">areas</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"41.5493%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.6338%\" x=\"46.4789%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">of</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"49.2958%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.4507%\" x=\"52.1127%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">skin</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"56.338%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.4507%\" x=\"60.5634%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">more</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJR</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7887%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.4507%\" x=\"69.0141%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">than</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"73.2394%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"9.85915%\" x=\"77.4648%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">twice</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">RB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.3944%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"12.6761%\" x=\"87.3239%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"44.4444%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"22.2222%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"55.5556%\" x=\"44.4444%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">day</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.2222%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"93.662%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [('Do', 'NNP'), ('not', 'RB'), ('wash', 'VB'), ('affected', 'JJ'), ('areas', 'NNS'), ('of', 'IN'), Tree('NP', [('skin', 'NN')]), ('more', 'JJR'), ('than', 'IN'), ('twice', 'RB'), Tree('NP', [('a', 'DT'), ('day', 'NN')])])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Do not wash affected areas of skin more than twice a day\"\n",
    "sent_tokens = nltk.pos_tag(word_tokenize(sentence))\n",
    "grammar = r\"NP:{<DT>?<JJ>*<NN>}\"\n",
    "chunk_parser = nltk.RegexpParser(grammar)\n",
    "chunk_parser.parse(sent_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:15:45.065320Z",
     "start_time": "2023-11-06T06:15:45.056211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (N stress)) (VP (V creates) (NP (N acne))))\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"216px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,184.0,216.0\" width=\"184px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"34.7826%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">N</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">stress</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"17.3913%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"65.2174%\" x=\"34.7826%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VP</text></svg><svg width=\"60%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">V</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">creates</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"40%\" x=\"60%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">N</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">acne</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.3913%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('NP', [Tree('N', ['stress'])]), Tree('VP', [Tree('V', ['creates']), Tree('NP', [Tree('N', ['acne'])])])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "NP -> N\n",
    "VP -> V NP\n",
    "N -> \"stress\" | \"acne\"\n",
    "V -> \"creates\"\n",
    "\"\"\")\n",
    "# example sentence that can be parsed with the grammar we've defined\n",
    "sent = nltk.word_tokenize(\"stress creates acne\")\n",
    "# create a chart parser based on the grammar above\n",
    "parser = nltk.ChartParser(grammar)\n",
    "# parse the sentence\n",
    "trees = list(parser.parse(sent))\n",
    "# print a text-formatted parse tree\n",
    "print(trees[0])\n",
    "# print an SVG formatted parse tree\n",
    "trees[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Develop search criteria for your project and perform slot filling and slot visualization.  (40 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:22.398362Z",
     "start_time": "2023-11-06T06:23:22.291741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cough', 'SYMPTOM'), ('today', 'RELATIVE_DATE'), ('home', 'LOCATION'), ('san francisco', 'LOCATION')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = English()\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "symptom_patterns = [\n",
    "    {\"label\": \"SYMPTOM\", \"pattern\": \"rash\"},\n",
    "    {\"label\": \"SYMPTOM\", \"pattern\": \"cough\"},\n",
    "    {\"label\": \"SYMPTOM\", \"pattern\": \"cold\"},\n",
    "    {\"label\": \"SYMPTOM\", \"pattern\": \"red eyes\"},\n",
    "    {\"label\": \"SYMPTOM\", \"pattern\": \"drowsy\"},\n",
    "    {\"label\": \"SYMPTOM\", \"pattern\": \"hair loss\"}]\n",
    "day_patterns = [\n",
    "    {\"label\": \"RELATIVE_DATE\", \"pattern\": \"today\"},\n",
    "    {\"label\": \"RELATIVE_DATE\", \"pattern\": \"yesterday\"},\n",
    "    {\"label\": \"RELATIVE_DATE\", \"pattern\": \"tomorrow\"}]\n",
    "location_patterns = [\n",
    "    {\"label\": \"LOCATION\", \"pattern\": \"home\"},\n",
    "    {\"label\": \"LOCATION\", \"pattern\": \"office\"},\n",
    "    {\"label\": \"LOCATION\", \"pattern\": \"san francisco\"},\n",
    "    {\"label\": \"LOCATION\", \"pattern\": \"stockton\"}]\n",
    "ruler.add_patterns(symptom_patterns)\n",
    "ruler.add_patterns(day_patterns)\n",
    "ruler.add_patterns(location_patterns)\n",
    "ruler.add_patterns(location_patterns)\n",
    "doc = nlp(\"I am having bad cough today. im in my home in san francisco\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-06T06:23:33.096389Z",
     "start_time": "2023-11-06T06:23:33.087066Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I am having bad \n",
       "<mark class=\"entity\" style=\"background: #ea7e7e; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cough\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">SYMPTOM</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #baffc9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    today\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">RELATIVE_DATE</span>\n",
       "</mark>\n",
       ". im in my \n",
       "<mark class=\"entity\" style=\"background: #ffffba; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    home\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOCATION</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #ffffba; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    san francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOCATION</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "colors = {\n",
    "    \"SYMPTOM\": \"#ea7e7e\",\n",
    "    \"RELATIVE_DATE\": \"#baffc9\",\n",
    "    \"LOCATION\": \"#ffffba\"\n",
    "}\n",
    "options = {\"ents\": [\"SYMPTOM\",\"RELATIVE_DATE\",\"LOCATION\"],\n",
    "           \"colors\": colors}\n",
    "displacy.render(doc, style=\"ent\", options=options,jupyter = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
